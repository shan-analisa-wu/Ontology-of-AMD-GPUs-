{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request as request\n",
    "import requests\n",
    "import re\n",
    "import urllib\n",
    "import time\n",
    "import random\n",
    "class ScrapeCpuAmd:\n",
    "    def __init__(self):\n",
    "        # call the parent constructor\n",
    "        # super().__init__(output_file)\n",
    "        pass\n",
    "\n",
    "    def from_crawler(cls, crawler):\n",
    "        return cls(crawler)\n",
    "\n",
    "    def find_pages(self, url, links_to_scrape):\n",
    "\n",
    "        temp_links_to_scrape = []\n",
    "        # returns a list of urls to pages to scrape\n",
    "        iplist = ['219.223.251.173:3128', '203.174.112.13:3128', '122.72.18.34:80','219.223.251.17:3128', '203.174.112.15:3128']\n",
    "        print(iplist[random.randint(0, len(iplist) - 1)])\n",
    "        ipaddr=iplist[random.randint(0, len(iplist) - 1)]\n",
    "        proxy_support = urllib.request.ProxyHandler({'http': ipaddr})\n",
    "        opener = urllib.request.build_opener(proxy_support)\n",
    "        opener = request.build_opener(proxy_support)\n",
    "        #opener.addheaders = [('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0')]\n",
    "        opener.addheaders = [('User-Agent', 'Chrome/49.0.2623.221')]\n",
    "\n",
    "        request.install_opener(opener)\n",
    "        response = request.urlopen(url)\n",
    "        html = response.read().decode(\"utf-8\")\n",
    "        soup = bs(html, 'html.parser')\n",
    "        # get all hyper links\n",
    "        for td in soup.find_all('td', attrs={'class': 'vendor-AMD'}):\n",
    "            curLink = td.find('a')\n",
    "            if curLink is not None:\n",
    "                temp_links_to_scrape.append(curLink)\n",
    "        for i in temp_links_to_scrape:\n",
    "            links_to_scrape.append(i.get(\"href\"))\n",
    "        time.sleep(3)\n",
    "\n",
    "    def scrape_page(self, url_to_scrape, out):\n",
    "        #         len(url_to_scrape)\n",
    "        count = 0\n",
    "        for i in range(0, len(url_to_scrape)):\n",
    "            cur_url = \"https://www.techpowerup.com\" + url_to_scrape[i]\n",
    "            data = {'Source': cur_url}\n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0'}\n",
    "            req = urllib.request.Request(cur_url, headers=headers)\n",
    "            #             webpages = request.urlopen(req)\n",
    "            #             if webpages.getcode() == 429:\n",
    "            #                 time.sleep(1800)\n",
    "            # add try catch\n",
    "            try:\n",
    "                webpages = request.urlopen(req)\n",
    "                html = webpages.read().decode(\"utf-8\")\n",
    "                soup = bs(html, 'html.parser')\n",
    "                #             with open(cur_url) as file:\n",
    "                #                 soup = bs(file, features=\"html.parser\")\n",
    "\n",
    "                for dl in soup.find_all('dl', attrs={'class': 'clearfix'}):\n",
    "                    key = dl.find('dt').get_text().strip()\n",
    "                    value = dl.find('dd').get_text().strip()\n",
    "                    data[key] = value\n",
    "\n",
    "                with open(out, \"a\") as file:\n",
    "                    json.dump(data, file)\n",
    "                count = count + 1\n",
    "                print(count)\n",
    "                time.sleep(60)\n",
    "            except:\n",
    "                print(\"here\")\n",
    "                time.sleep(1800)\n",
    "\n",
    "\n",
    "links_to_scrape = []\n",
    "scrape = ScrapeCpuAmd()\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2006&sort=name\", links_to_scrape)\n",
    "#time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2007&sort=name\", links_to_scrape)\n",
    "#time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2008&sort=name\", links_to_scrape)\n",
    "#time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2009&sort=name\", links_to_scrape)\n",
    "#time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2010&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2011&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2012&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2014&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2015&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2016&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2017&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2018&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2019&sort=name\", links_to_scrape)\n",
    "# time.sleep(30)\n",
    "scrape.find_pages(\"https://www.techpowerup.com/gpu-specs/?mfgr=AMD&released=2020&sort=name\", links_to_scrape)\n",
    "print(links_to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape.scrape_page(links_to_scrape, \"new_result.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_to_scrape = ['https://www.techpowerup.com/gpu-specs/firepro-s10000.c802','https://www.techpowerup.com/gpu-specs/firepro-s9150.c2608',\n",
    "                  'https://www.techpowerup.com/gpu-specs/radeon-hd-7970.c296', 'https://www.techpowerup.com/gpu-specs/amd-vega-20.g848', \n",
    "                  'https://www.techpowerup.com/gpu-specs/radeon-hd-5870.c253', 'https://www.techpowerup.com/cpu-specs/xeon-phi-3120p.c2031', \n",
    "                  'https://www.techpowerup.com/cpu-specs/xeon-phi-31s1p.c2032', 'https://www.techpowerup.com/gpu-specs/xeon-phi-5110p.c2480', \n",
    "                  'https://www.techpowerup.com/gpu-specs/xeon-phi-5120d.c2482', 'https://www.techpowerup.com/cpu-specs/xeon-phi-7110p.c2035', \n",
    "                  'https://www.techpowerup.com/cpu-specs/xeon-phi-7120p.c2039', 'https://www.techpowerup.com/gpu-specs/xeon-phi-7120x.c2481', \n",
    "                  'https://www.techpowerup.com/cpu-specs/xeon-phi-se10p.c2033', 'https://www.techpowerup.com/cpu-specs/xeon-phi-se10x.c2034', \n",
    "                  'https://www.techpowerup.com/gpu-specs/xeon-phi-5110p.c2480', 'https://www.techpowerup.com/gpu-specs/xeon-phi-7120p.c1885', \n",
    "                  'https://www.techpowerup.com/gpu-specs/tesla-k20x.c2315', 'https://www.techpowerup.com/gpu-specs/tesla-k40m.c2529', \n",
    "                  'https://www.techpowerup.com/gpu-specs/nvidia-gp100.g792', 'https://www.techpowerup.com/gpu-specs/xeon-phi-7120p.c1885', \n",
    "                  'https://www.techpowerup.com/gpu-specs/tesla-k20x.c2315', 'https://www.techpowerup.com/gpu-specs/tesla-k40s.c2528', \n",
    "                  'https://www.techpowerup.com/gpu-specs/tesla-k80.c2616', 'https://www.techpowerup.com/gpu-specs/tesla-p100-pcie-16-gb.c2888', \n",
    "                  'https://www.techpowerup.com/gpu-specs/tesla-p4.c2879', 'https://www.techpowerup.com/gpu-specs/tesla-v100-sxm2-16-gb.c3018', \n",
    "                  'https://www.techpowerup.com/gpu-specs/geforce-gtx-titan-black.c2549', 'https://www.techpowerup.com/gpu-specs/quadro-gv100.c3066', \n",
    "                  'https://www.techpowerup.com/gpu-specs/xeon-phi-5120d.c2482']\n",
    "def scrape_page(self, url_to_scrape, out):\n",
    "        #         len(url_to_scrape)\n",
    "        count = 0\n",
    "        for i in range(0, len(url_to_scrape)):\n",
    "            cur_url = url_to_scrape[i]\n",
    "            data = {'Source': cur_url}\n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0'}\n",
    "            req = urllib.request.Request(cur_url, headers=headers)\n",
    "            #             webpages = request.urlopen(req)\n",
    "            #             if webpages.getcode() == 429:\n",
    "            #                 time.sleep(1800)\n",
    "            # add try catch\n",
    "            try:\n",
    "                webpages = request.urlopen(req)\n",
    "                html = webpages.read().decode(\"utf-8\")\n",
    "                soup = bs(html, 'html.parser')\n",
    "                #             with open(cur_url) as file:\n",
    "                #                 soup = bs(file, features=\"html.parser\")\n",
    "\n",
    "                for dl in soup.find_all('dl', attrs={'class': 'clearfix'}):\n",
    "                    key = dl.find('dt').get_text().strip()\n",
    "                    value = dl.find('dd').get_text().strip()\n",
    "                    data[key] = value\n",
    "\n",
    "                with open(out, \"a\") as file:\n",
    "                    json.dump(data, file)\n",
    "                count = count + 1\n",
    "                print(count)\n",
    "                time.sleep(60)\n",
    "            except:\n",
    "                print(\"here\")\n",
    "                time.sleep(1800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
